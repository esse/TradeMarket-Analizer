#!/usr/bin/python
# -*- coding: utf-8 -*-

###
# Grzegorz Wieczorek 07.09.2009 00:43
# gg: 5905482
# jabb: grzew@jabster.pl
# email: grzewster@gmail.com
# 
###

import urllib2
import BeautifulSoup
import re
import sys

zmienne=[]

for arg in sys.argv:
    zmienne.append(arg)

dzien = zmienne[1]
miesiac = zmienne[2]
rok = zmienne[3]


class wiki_parser:
 
    def mydelniczka(self,url):
            request = urllib2.Request(url)
            user_agent = "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.1.14) Gecko/20080418 Ubuntu/7.10 (gutsy) Firefox/2.0.0.14"
            request.add_header("User-Agent", user_agent)
            pagefile=urllib2.urlopen(request)
            soup=BeautifulSoup.BeautifulSoup(pagefile)
            realurl = pagefile.geturl()
            pagefile.close()
            return (soup, realurl)

    def oczyszczarka(self,value):
        return re.sub(r'<[^>]*?>', '', value) 

    def dzialaj(self,rok, miesiac,dzien):
        strona = "http://en.wikipedia.org/wiki/Portal:Current_events/"+rok+"_"+miesiac+"_"+dzien    
        (soup, url) = self.mydelniczka(strona)
        for ul in soup.findAll("td", { "class" : "description" } ):
            wyniki = self.oczyszczarka(str(ul)).split("\n")
        return wyniki

w = wiki_parser()
lista = w.dzialaj(rok,miesiac,dzien)

print lista[2]
